# Reference
- [functorch README](https://github.com/pytorch/pytorch/tree/master/functorch)
- [functorch writing_batching_rules](https://github.com/pytorch/pytorch/blob/master/functorch/writing_batching_rules.md)

# TODO
- go thru other transformations in functorch README
  - jvp, vjp, jacrev, jacfwd, hessian, `make_functional`

# Done
- understand vmap
- roughly understand grad: used TensorWrapper and calls torch.autograd.grad
- roughly understand `aot_autograd`
